{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## Entendendo o GPT\n",
    "\n",
    "O GPT é uma LLM (Large Language Models), ou seja, um modelo de aprendizado profundo especializado em processamento de linguagem natural. Baseado na arquitetura de transformadores, ele é treinado com grandes volumes de texto para entender e gerar respostas a prompts ou perguntas fornecidas pelo usuário.\n",
    "\n",
    "São alguns exemplos de LLM:\n",
    "- GPT (Generative Pre-trained Transformer) - OpenAI\n",
    "- BERT (Bidirectional Encoder Representations from Transformers) - Google AI\n",
    "- RoBERTa (A Robustly Optimized BERT Pretraining Approach) - Facebook AI\n",
    "- ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) - Google Research\n",
    "- Megatron-LM - NVIDIA\n",
    "- DeBERTa (Decoding-enhanced BERT with disentangled attention) - Microsoft Research\n",
    "- Turing-NLG - Microsoft\n",
    "\n",
    "O GPT possui mais de um modelo, sendo os mais famosos GPT-3.5 e o GPT-4. A OpenAI possui outros modelos como DaVinci, Curie, Ada, etc. \n",
    "[Lista dos Modelos do OpenAI](https://platform.openai.com/docs/models)\n",
    "\n",
    "\n",
    "Para utilizar uma LLM, passamos uma instrução (prompt) solicitando uma resposta ou ação. O prompt pode ser um pedido ou um questionamento.\n",
    "\n",
    "Exemplos:\n",
    "- **Q&A:** \"Qual é a capital da França?\";\n",
    "- **Criação de Texto:** \"Escreva um poema sobre a primavera.\";\n",
    "- **Instrução:** \"Transforme a seguinte frase para voz passiva: 'O gato perseguiu o rato.'\";\n",
    "\n",
    "Este prompt será convertido em tokens que representam uma unidade de informação. Um token pode ser tão curto quanto uma letra e tão longo quanto uma palavra, dependendo do contexto e do idioma.\n",
    "\n",
    "Em média, 100 tokens equivalem a aproximadamente 75 palavras. É possível verificar a quantidade de tokens neste [Link](https://platform.openai.com/tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando os módulos necessários.\n",
    "- python-dotenv para ler as configurações do arquivo .env\n",
    "- openai para acessar a API do ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (1.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (0.27.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando para as chamadas\n",
    "Iremos importar as bibliotecas necessárias e passar o valor da chave do OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de chamada do OpenAI\n",
    "Após informar a sua chave do OpenAI, basta realizar a chamada informando o modelo, as mensagens e a temperatura.\n",
    "\n",
    "Há vários modelos do OpenAI que podem ser utilizados. Cada um com custos diferentes e com propósitos diferentes.\n",
    "- **Série GPT3**\n",
    "\t- **text-ada-001:** Utilizado para tarefas simples, normalmente mais rápido que o GPT3 com custo mais baixo.\n",
    "\t\t- Ideal para análise de textos, classificações simples, correções de endereço e palavras-chave.\n",
    "\t- **text-babbage-001:** Utilizado para tarefas simples com baixo custo.\n",
    "\t\t- Ideal para classificações moderadas e buscas semânticas.\n",
    "\t- **text-curie-001:** Muito capaz, mais rápido e mais barato que o text-davinci-003.\n",
    "\t\t- Ideal para tradução de idiomas, classificação complexa e sumarização de sentimentos.\n",
    "- **Série GPT3.5**\n",
    "\t- **text-davinci-edit-001:** Modelo especializado para editar textos.\n",
    "\t\t- Ideal para alterar um texto conforme a instrução dada.\n",
    "\t- **code-davinci-edit-001:** Modelo especializado para editar códigos.\n",
    "\t\t- Ideal para alterar um código conforme a instrução dada.\n",
    "\t- **text-davinci-003:** Realiza tarefas com mais qualidade, com saídas mais extensas e com melhores instruções.\n",
    "\t\t- Ideal para identificar intenção complexa, causa e efeito, geração criativa e sumarização de pesquisas.\n",
    "\t- **gpt-3.5-turbo:** O modelo GPT-3.5 mais capaz e otimizado para chat a 1/10 do custo do text-davinci-003.\n",
    "\t\t- Ideal para identificar intenção complexa, causa e efeito, geração criativa e sumarização de pesquisas.\n",
    "- **Série GPT4**\n",
    "\t- **gpt-4:** Mais capaz do que qualquer modelo GPT-3.5, apto a realizar tarefas mais complexas e otimizado para chat.\n",
    "\n",
    "Compare as diferença de respostas para uma mesma pergunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = \"Descreva os potenciais impactos das mudanças climáticas na economia global ao longo do século 21.\"\n",
    "input = \"Responda em formato de verso. Qual a capital do Brasil?\"\n",
    "messages = [{\"role\": \"user\", \"content\": input}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-ada-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brasília\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nBras\\u00edlia\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711929,\n",
      "    \"id\": \"cmpl-7qLzFV94IGMC1t9erXSoLQoWXGkec\",\n",
      "    \"model\": \"text-ada-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 6,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 22\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-ada-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-babbage-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brasília.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nBras\\u00edlia.\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711936,\n",
      "    \"id\": \"cmpl-7qLzMB2tD5f7CD7LC74ikT1D5nbmh\",\n",
      "    \"model\": \"text-babbage-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 23\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-babbage-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-curie-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A capital do Brasil é Brasília.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nA capital do Brasil \\u00e9 Bras\\u00edlia.\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711947,\n",
      "    \"id\": \"cmpl-7qLzXisg73ENzHonCWFN7jKcVcX3A\",\n",
      "    \"model\": \"text-curie-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 12,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 28\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-curie-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Brasília, a capital do Brasil\n",
      "A terra do sol que nasceu para brilhar\"\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\n\\\"Bras\\u00edlia, a capital do Brasil\\nA terra do sol que nasceu para brilhar\\\"\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711954,\n",
      "    \"id\": \"cmpl-7qLzeow9Tb3vzQv6UTE4n7Ai1PnNO\",\n",
      "    \"model\": \"text-davinci-003\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 28,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 44\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-davinci-003\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília é a capital do Brasil,\n",
      "Um lugar de beleza sem igual.\n",
      "Com sua arquitetura moderna,\n",
      "No coração do Planalto Central.\n",
      "\n",
      "Lá estão os poderes do país,\n",
      "Onde a história se faz presente.\n",
      "Política, cultura e diversidade,\n",
      "Em cada canto, um encanto latente.\n",
      "\n",
      "Brasília, cidade planejada,\n",
      "Com suas avenidas largas e retas.\n",
      "Um símbolo de progresso e inovação,\n",
      "No centro do país, entre florestas.\n",
      "\n",
      "É lá que se encontra o poder,\n",
      "Onde as decisões são tomadas.\n",
      "A capital do Brasil, orgulho nacional,\n",
      "Um lugar que não pode ser esquecido.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Bras\\u00edlia \\u00e9 a capital do Brasil,\\nUm lugar de beleza sem igual.\\nCom sua arquitetura moderna,\\nNo cora\\u00e7\\u00e3o do Planalto Central.\\n\\nL\\u00e1 est\\u00e3o os poderes do pa\\u00eds,\\nOnde a hist\\u00f3ria se faz presente.\\nPol\\u00edtica, cultura e diversidade,\\nEm cada canto, um encanto latente.\\n\\nBras\\u00edlia, cidade planejada,\\nCom suas avenidas largas e retas.\\nUm s\\u00edmbolo de progresso e inova\\u00e7\\u00e3o,\\nNo centro do pa\\u00eds, entre florestas.\\n\\n\\u00c9 l\\u00e1 que se encontra o poder,\\nOnde as decis\\u00f5es s\\u00e3o tomadas.\\nA capital do Brasil, orgulho nacional,\\nUm lugar que n\\u00e3o pode ser esquecido.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711998,\n",
      "    \"id\": \"chatcmpl-7qM0MY4HzU5qBLYkLwfeAu4Q9mtZh\",\n",
      "    \"model\": \"gpt-3.5-turbo-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 150,\n",
      "        \"prompt_tokens\": 21,\n",
      "        \"total_tokens\": 171\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7\n",
    ")\n",
    "print(response.choices[0].message[\"content\"])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília é a capital, sem igual,\n",
      "Do nosso querido Brasil tropical.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Bras\\u00edlia \\u00e9 a capital, sem igual,\\nDo nosso querido Brasil tropical.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692712024,\n",
      "    \"id\": \"chatcmpl-7qM0mC6uy1TI8T16j3942acDYsmHj\",\n",
      "    \"model\": \"gpt-4-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 21,\n",
      "        \"total_tokens\": 38\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-4\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles \n",
    "\n",
    "Para os modelos do GPT-3.5 e GPT-4, é possível definir as roles. Ou seja, o modelo consegue identificar os tipos abaixo:\n",
    "- user: iteração do usuário;\n",
    "- assistant: resposta do openAI\n",
    "\n",
    "- system: diretriz de como o openAI deverá responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em terras distantes além do mar,\n",
      "Onde o sol é ardente a brilhar,\n",
      "Existe um lugar de beleza sem par,\n",
      "Brasília é seu nome a se aclamar.\n",
      "\n",
      "No coração do país ela se encontra,\n",
      "Com arquitetura que nossa vista apronta,\n",
      "A capital, com orgulho, se desfruta,\n",
      "Nas terras verdes da bela conduta.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Em terras distantes al\\u00e9m do mar,\\nOnde o sol \\u00e9 ardente a brilhar,\\nExiste um lugar de beleza sem par,\\nBras\\u00edlia \\u00e9 seu nome a se aclamar.\\n\\nNo cora\\u00e7\\u00e3o do pa\\u00eds ela se encontra,\\nCom arquitetura que nossa vista apronta,\\nA capital, com orgulho, se desfruta,\\nNas terras verdes da bela conduta.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692712038,\n",
      "    \"id\": \"chatcmpl-7qM10fgVK3qMK9zEeyckq1cSvDvCO\",\n",
      "    \"model\": \"gpt-4-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 88,\n",
      "        \"prompt_tokens\": 35,\n",
      "        \"total_tokens\": 123\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"Você é um menestrel da idade média e deverá responder usando versos.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Qual a capital do Brasil?\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-4\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperatura\n",
    "\n",
    "A temperatura defini o grau de liberdade para criatividade (ou aleatoriedade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero aleatoriedade\n",
      "Sim, essa frase é falsa.\n",
      "\n",
      "Muita aleatoriedade\n",
      "A frase \"Esta frase é falsa\" é uma frase paradoxal ou auto-referencial, onde não pode ser determinado como verdadeira ou falsa. Isso ocorre porque se a frase afirma ser falsa, então ela deveria ser verdadeira. E se a frase é verdadeira, então ela está dizendo que é falsa, o que torna paradoxal. Por essa razão, a frase não pode ser classificada como verdadeira ou falsa.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Esta frase é falsa?\"},]\n",
    "print('Zero aleatoriedade')\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "\n",
    "print()\n",
    "print('Muita aleatoriedade')\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=1\n",
    ")\n",
    "print(response.choices[0].message['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
