{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## Entendendo o GPT\n",
    "\n",
    "O GPT é uma LLM (Large Language Models), ou seja, um modelo de aprendizado profundo especializado em processamento de linguagem natural. Baseado na arquitetura de transformadores, ele é treinado com grandes volumes de texto para entender e gerar respostas a prompts ou perguntas fornecidas pelo usuário.\n",
    "\n",
    "São alguns exemplos de LLM:\n",
    "- GPT (Generative Pre-trained Transformer) - OpenAI\n",
    "- BERT (Bidirectional Encoder Representations from Transformers) - Google AI\n",
    "- RoBERTa (A Robustly Optimized BERT Pretraining Approach) - Facebook AI\n",
    "- ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) - Google Research\n",
    "- Megatron-LM - NVIDIA\n",
    "- DeBERTa (Decoding-enhanced BERT with disentangled attention) - Microsoft Research\n",
    "- Turing-NLG - Microsoft\n",
    "\n",
    "O GPT possui mais de um modelo, sendo os mais famosos GPT-3.5 e o GPT-4. A OpenAI possui outros modelos como DaVinci, Curie, Ada, etc. \n",
    "[Lista dos Modelos do OpenAI](https://platform.openai.com/docs/models)\n",
    "\n",
    "Para utilizar uma LLM, passamos uma instrução (prompt) solicitando uma resposta ou ação. O prompt pode ser um pedido ou um questionamento.\n",
    "\n",
    "É possível pedir para o GPT:\n",
    "- Rascunhar documentos\n",
    "- Escrever código de computador\n",
    "- Responder perguntas sobre uma base de conhecimento\n",
    "- Analisar textos\n",
    "- Criar agentes conversacionais\n",
    "- Dar ao software uma interface de linguagem natural\n",
    "- Tutorar em uma variedade de assuntos\n",
    "- Traduzir idiomas\n",
    "- Simular personagens para jogos\n",
    "\n",
    "Exemplos:\n",
    "- **Q&A:** \"Qual é a capital da França?\";\n",
    "- **Criação de Texto:** \"Escreva um poema sobre a primavera.\";\n",
    "- **Instrução:** \"Transforme a seguinte frase para voz passiva: 'O gato perseguiu o rato.'\";\n",
    "\n",
    "Este prompt será convertido em tokens que representam uma unidade de informação. Um token pode ser tão curto quanto uma letra e tão longo quanto uma palavra, dependendo do contexto e do idioma.\n",
    "\n",
    "Em média, 100 tokens equivalem a aproximadamente 75 palavras. É possível verificar a quantidade de tokens neste [Link](https://platform.openai.com/tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando os módulos necessários.\n",
    "- python-dotenv para ler as configurações do arquivo .env\n",
    "- openai para acessar a API do ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (1.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (0.27.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmart\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando para as chamadas\n",
    "Iremos importar as bibliotecas necessárias e passar o valor da chave do OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de chamada do OpenAI\n",
    "Após informar a sua chave do OpenAI, basta realizar a chamada informando o modelo, as mensagens e a temperatura.\n",
    "\n",
    "Há vários modelos do OpenAI que podem ser utilizados. Cada um com custos diferentes e com propósitos diferentes.\n",
    "- **Série GPT3**\n",
    "\t- **text-ada-001:** Utilizado para tarefas simples, normalmente mais rápido que o GPT3 com custo mais baixo.\n",
    "\t\t- Ideal para análise de textos, classificações simples, correções de endereço e palavras-chave.\n",
    "\t- **text-babbage-001:** Utilizado para tarefas simples com baixo custo.\n",
    "\t\t- Ideal para classificações moderadas e buscas semânticas.\n",
    "\t- **text-curie-001:** Muito capaz, mais rápido e mais barato que o text-davinci-003.\n",
    "\t\t- Ideal para tradução de idiomas, classificação complexa e sumarização de sentimentos.\n",
    "- **Série GPT3.5**\n",
    "\t- **text-davinci-edit-001:** Modelo especializado para editar textos.\n",
    "\t\t- Ideal para alterar um texto conforme a instrução dada.\n",
    "\t- **code-davinci-edit-001:** Modelo especializado para editar códigos.\n",
    "\t\t- Ideal para alterar um código conforme a instrução dada.\n",
    "\t- **text-davinci-003:** Realiza tarefas com mais qualidade, com saídas mais extensas e com melhores instruções.\n",
    "\t\t- Ideal para identificar intenção complexa, causa e efeito, geração criativa e sumarização de pesquisas.\n",
    "\t- **gpt-3.5-turbo:** O modelo GPT-3.5 mais capaz e otimizado para chat a 1/10 do custo do text-davinci-003.\n",
    "\t\t- Ideal para identificar intenção complexa, causa e efeito, geração criativa e sumarização de pesquisas.\n",
    "- **Série GPT4**\n",
    "\t- **gpt-4:** Mais capaz do que qualquer modelo GPT-3.5, apto a realizar tarefas mais complexas e otimizado para chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare as diferença de respostas de cada modelo para a mesma pergunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = \"Descreva os potenciais impactos das mudanças climáticas na economia global ao longo do século 21.\"\n",
    "input = \"Responda em formato de verso. Qual a capital do Brasil?\"\n",
    "messages = [{\"role\": \"user\", \"content\": input}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-ada-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brasília\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nBras\\u00edlia\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711929,\n",
      "    \"id\": \"cmpl-7qLzFV94IGMC1t9erXSoLQoWXGkec\",\n",
      "    \"model\": \"text-ada-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 6,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 22\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-ada-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-babbage-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brasília.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nBras\\u00edlia.\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711936,\n",
      "    \"id\": \"cmpl-7qLzMB2tD5f7CD7LC74ikT1D5nbmh\",\n",
      "    \"model\": \"text-babbage-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 23\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-babbage-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-curie-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A capital do Brasil é Brasília.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nA capital do Brasil \\u00e9 Bras\\u00edlia.\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711947,\n",
      "    \"id\": \"cmpl-7qLzXisg73ENzHonCWFN7jKcVcX3A\",\n",
      "    \"model\": \"text-curie-001\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 12,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 28\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-curie-001\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Brasília, a capital do Brasil\n",
      "A terra do sol que nasceu para brilhar\"\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\n\\\"Bras\\u00edlia, a capital do Brasil\\nA terra do sol que nasceu para brilhar\\\"\"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711954,\n",
      "    \"id\": \"cmpl-7qLzeow9Tb3vzQv6UTE4n7Ai1PnNO\",\n",
      "    \"model\": \"text-davinci-003\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 28,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 44\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-davinci-003\",\n",
    "\tprompt=input,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília é a capital do Brasil,\n",
      "Um lugar de beleza sem igual.\n",
      "Com sua arquitetura moderna,\n",
      "No coração do Planalto Central.\n",
      "\n",
      "Lá estão os poderes do país,\n",
      "Onde a história se faz presente.\n",
      "Política, cultura e diversidade,\n",
      "Em cada canto, um encanto latente.\n",
      "\n",
      "Brasília, cidade planejada,\n",
      "Com suas avenidas largas e retas.\n",
      "Um símbolo de progresso e inovação,\n",
      "No centro do país, entre florestas.\n",
      "\n",
      "É lá que se encontra o poder,\n",
      "Onde as decisões são tomadas.\n",
      "A capital do Brasil, orgulho nacional,\n",
      "Um lugar que não pode ser esquecido.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Bras\\u00edlia \\u00e9 a capital do Brasil,\\nUm lugar de beleza sem igual.\\nCom sua arquitetura moderna,\\nNo cora\\u00e7\\u00e3o do Planalto Central.\\n\\nL\\u00e1 est\\u00e3o os poderes do pa\\u00eds,\\nOnde a hist\\u00f3ria se faz presente.\\nPol\\u00edtica, cultura e diversidade,\\nEm cada canto, um encanto latente.\\n\\nBras\\u00edlia, cidade planejada,\\nCom suas avenidas largas e retas.\\nUm s\\u00edmbolo de progresso e inova\\u00e7\\u00e3o,\\nNo centro do pa\\u00eds, entre florestas.\\n\\n\\u00c9 l\\u00e1 que se encontra o poder,\\nOnde as decis\\u00f5es s\\u00e3o tomadas.\\nA capital do Brasil, orgulho nacional,\\nUm lugar que n\\u00e3o pode ser esquecido.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692711998,\n",
      "    \"id\": \"chatcmpl-7qM0MY4HzU5qBLYkLwfeAu4Q9mtZh\",\n",
      "    \"model\": \"gpt-3.5-turbo-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 150,\n",
      "        \"prompt_tokens\": 21,\n",
      "        \"total_tokens\": 171\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7\n",
    ")\n",
    "print(response.choices[0].message[\"content\"])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília é a capital, sem igual,\n",
      "Do nosso querido Brasil tropical.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Bras\\u00edlia \\u00e9 a capital, sem igual,\\nDo nosso querido Brasil tropical.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692712024,\n",
      "    \"id\": \"chatcmpl-7qM0mC6uy1TI8T16j3942acDYsmHj\",\n",
      "    \"model\": \"gpt-4-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 21,\n",
      "        \"total_tokens\": 38\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-4\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles \n",
    "\n",
    "Para os modelos do GPT-3.5 e GPT-4, é possível definir as roles. Ou seja, o modelo consegue identificar os tipos abaixo:\n",
    "- **user:** iteração do usuário;\n",
    "- **assistant:** resposta do openAI\n",
    "- **system:** diretriz de como o openAI deverá responder\n",
    "\n",
    "A mensagem do sistema ajuda a definir o comportamento do assistente. Por exemplo, você pode modificar a personalidade do assistente ou fornecer instruções específicas sobre como ele deve se comportar ao longo da conversa. No entanto, note que a mensagem do sistema é opcional e o comportamento do modelo sem uma mensagem do sistema provavelmente será semelhante ao uso de uma mensagem genérica, como \"Você é um assistente útil.\"\n",
    "\n",
    "As mensagens do usuário fornecem solicitações ou comentários para o assistente responder. Mensagens do assistente armazenam respostas anteriores do assistente, mas também podem ser escritas por você para dar exemplos de comportamento desejado.\n",
    "\n",
    "Incluir o histórico da conversa é importante quando as instruções do usuário se referem a mensagens anteriores. Como os modelos não têm memória de solicitações passadas, todas as informações relevantes devem ser fornecidas como parte do histórico da conversa em cada solicitação. Se uma conversa não puder se encaixar no limite de tokens do modelo, ela precisará ser encurtada de alguma forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em terras distantes além do mar,\n",
      "Onde o sol é ardente a brilhar,\n",
      "Existe um lugar de beleza sem par,\n",
      "Brasília é seu nome a se aclamar.\n",
      "\n",
      "No coração do país ela se encontra,\n",
      "Com arquitetura que nossa vista apronta,\n",
      "A capital, com orgulho, se desfruta,\n",
      "Nas terras verdes da bela conduta.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Em terras distantes al\\u00e9m do mar,\\nOnde o sol \\u00e9 ardente a brilhar,\\nExiste um lugar de beleza sem par,\\nBras\\u00edlia \\u00e9 seu nome a se aclamar.\\n\\nNo cora\\u00e7\\u00e3o do pa\\u00eds ela se encontra,\\nCom arquitetura que nossa vista apronta,\\nA capital, com orgulho, se desfruta,\\nNas terras verdes da bela conduta.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692712038,\n",
      "    \"id\": \"chatcmpl-7qM10fgVK3qMK9zEeyckq1cSvDvCO\",\n",
      "    \"model\": \"gpt-4-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 88,\n",
      "        \"prompt_tokens\": 35,\n",
      "        \"total_tokens\": 123\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"Você é um menestrel da idade média e deverá responder usando versos.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Qual a capital do Brasil?\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-4\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fornecendo exemplos através das roles\n",
    "Para adequar mais a resposta, é possível utilizar as roles para dar exemplo de como deverá ser as respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem exemplos\n",
      "A expressão \"abestalhado\" é uma gíria nordestina que significa alguém desajeitado, bobo ou desprovido de habilidade. Já o termo \"fuleiro\" é usado para descrever algo de baixa qualidade, malfeito ou sem valor. Nesse contexto, a frase significa que alguém tentou te dar um objeto de má qualidade ou pouco útil.\n",
      "\n",
      "Com exemplos:\n",
      "O tolo quis me dar este item de má qualidade.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"O tolo quis me dar este item de m\\u00e1 qualidade.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692744861,\n",
      "    \"id\": \"chatcmpl-7qUYPX477tS1tgHVdL9RFfg1MLJz1\",\n",
      "    \"model\": \"gpt-3.5-turbo-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 12,\n",
      "        \"prompt_tokens\": 115,\n",
      "        \"total_tokens\": 127\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('Sem exemplos')\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"Você é um assitente que ajudará a entender gírias nordestias.\"},\n",
    "  {\"role\": \"user\", \"content\": \"O abestalhado quis me dar este item fuleiro.\"},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message['content'])\n",
    "print()\n",
    "print('Com exemplos:')\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"Você é um assitente que ajudará a entender gírias nordestias.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Mas aquele cabra é muito arretado.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_assistant\", \"content\": \"Mas ele é muito bravo.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Estavam mangando daquele tabacudo.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_assistant\", \"content\": \"Estavam rindo daquele bobo.\"},\n",
    "  {\"role\": \"user\", \"content\": \"O abestalhado quis me dar este item fuleiro.\"},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message['content'])\n",
    "\n",
    "print('\\n' + '='*50 + '\\n')\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperatura\n",
    "\n",
    "A temperatura defini o grau de liberdade para criatividade (ou aleatoriedade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero aleatoriedade\n",
      "Sim, essa frase é falsa.\n",
      "\n",
      "Muita aleatoriedade\n",
      "A frase \"Esta frase é falsa\" é uma frase paradoxal ou auto-referencial, onde não pode ser determinado como verdadeira ou falsa. Isso ocorre porque se a frase afirma ser falsa, então ela deveria ser verdadeira. E se a frase é verdadeira, então ela está dizendo que é falsa, o que torna paradoxal. Por essa razão, a frase não pode ser classificada como verdadeira ou falsa.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Esta frase é falsa?\"},]\n",
    "print('Zero aleatoriedade')\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "\n",
    "print()\n",
    "print('Muita aleatoriedade')\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=1\n",
    ")\n",
    "print(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish Reasons\n",
    "\n",
    "Cada resposta tem um motivo de finalização (finish reason). Eles podem ser:\n",
    "- **stop:** A API retornou uma mensagem completa ou uma mensagem terminada por uma das sequências de parada fornecidas pelo parâmetro stop.\n",
    "- **length:** Saída incompleta do modelo devido ao parâmetro max_tokens ou limite de tokens.\n",
    "- **function_call:** O modelo decidiu chamar uma função.\n",
    "- **content_filter:** Conteúdo omitido devido a uma sinalização de filtros de conteúdo.\n",
    "- **null:** Resposta da API ainda em andamento ou incompleta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A letra do Hino Nacional do Brasil é a seguinte:\n",
      "\n",
      "Ouviram do \n",
      "motivo da parada:stop\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Qual é a letra do Hino do Brasil?\"},]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tstop=[\"Ipiranga\"],\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print('motivo da parada:' +response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A letra do Hino do Brasil é a seguinte:\n",
      "\n",
      "Ouviram do Ipiranga as margens plácidas\n",
      "De um povo\n",
      "motivo da parada:length\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Qual é a letra do Hino do Brasil?\"},]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=30,\n",
    ")\n",
    "print(response.choices[0].message['content'])\n",
    "print('motivo da parada:' +response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "O dobro de 25 é 50.\n",
      "motivo da parada:function_call\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Qual é o dobro de 25?\"},]\n",
    "\n",
    "def get_double(number):\n",
    "\t\"\"\"Get the double of a number\"\"\"\n",
    "\tdouble = {\n",
    "\t\t\"number\": int(number) * 2,\n",
    "\t}\n",
    "\treturn json.dumps(double)\n",
    "\n",
    "functions = [\n",
    "\t{\n",
    "    \t\"name\": \"get_double\",\n",
    "\t\t\"description\": \"Get the double of a number\",\n",
    "\t\t\"parameters\": {\n",
    "\t\t\t\"type\": \"object\",\n",
    "\t\t\t\"properties\": {\n",
    "\t\t\t\t\"number\": {\n",
    "\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\"description\": \"Number to be doubled, e.g. '4'\",\n",
    "\t\t\t\t}\n",
    "\t\t\t},\n",
    "            \"required\": [\"number\"],\n",
    "\t\t},\n",
    "\t}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tfunctions=functions,\n",
    ")\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "if response_message.get(\"function_call\"):\n",
    "\tavailable_functions = {\n",
    "            \"get_double\": get_double,\n",
    "\t}\n",
    "\tfunction_name = response_message[\"function_call\"][\"name\"]\n",
    "\tfuction_to_call = available_functions[function_name]\n",
    "\tfunction_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "\tfunction_response = fuction_to_call(\n",
    "            number=function_args.get(\"number\")\n",
    "\t)\n",
    "\n",
    "\tmessages.append(response_message)\n",
    "\tmessages.append(\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"function\",\n",
    "\t\t\t\"name\": function_name,\n",
    "\t\t\t\"content\": function_response,\n",
    "\t\t}\n",
    "\t)\n",
    "\tsecond_response = openai.ChatCompletion.create(\n",
    "\t\tmodel=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "\t)\n",
    "\n",
    "\tprint(second_response.choices[0].message['content'])\n",
    "print('motivo da parada:' +response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### content_filter\n",
    "São situações muito específicas em que o chatGPT entende que está indo contra as políticas. Não consegui fazer nenhuma simulação desta situação\n",
    "\n",
    "#### null\n",
    ":** Resposta da API ainda em andamento ou incompleta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choices\n",
    "\n",
    "Também é possível solicitar mais de uma resposta na mesma request. Para isto, basta informar o parâmetro n com a quantidade de respostas desejadas.\n",
    "\n",
    "Importante lembrar que isto aumentará significativamente a quantidade de tokens, consequentemente, o preço da chamada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta1: O Brasil é conhecido por suas belezas naturais, cultura diversificada e pelo futebol.\n",
      "Resposta2: O Brasil é conhecido por suas belas praias, sua diversidade cultural e sua paixão pelo futebol.\n",
      "Resposta3: O Brasil é conhecido por sua cultura diversificada, suas belas praias, sua paixão pelo futebol e sua rica biodiversidade.\n",
      "Resposta4: O Brasil é conhecido por sua cultura diversa, suas belezas naturais, seu futebol talentoso e sua música contagiante.\n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"O Brasil \\u00e9 conhecido por suas belezas naturais, cultura diversificada e pelo futebol.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 1,\n",
      "            \"message\": {\n",
      "                \"content\": \"O Brasil \\u00e9 conhecido por suas belas praias, sua diversidade cultural e sua paix\\u00e3o pelo futebol.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 2,\n",
      "            \"message\": {\n",
      "                \"content\": \"O Brasil \\u00e9 conhecido por sua cultura diversificada, suas belas praias, sua paix\\u00e3o pelo futebol e sua rica biodiversidade.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 3,\n",
      "            \"message\": {\n",
      "                \"content\": \"O Brasil \\u00e9 conhecido por sua cultura diversa, suas belezas naturais, seu futebol talentoso e sua m\\u00fasica contagiante.\",\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692742135,\n",
      "    \"id\": \"chatcmpl-7qTqRsdBowUgc100mqlKSG0AuRZln\",\n",
      "    \"model\": \"gpt-3.5-turbo-0613\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 116,\n",
      "        \"prompt_tokens\": 19,\n",
      "        \"total_tokens\": 135\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Complete a frase: O Brasil é conhecido por...?\"},]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=messages,\n",
    "\ttemperature=0.7,\n",
    "\tn=4,\n",
    ")\n",
    "i=0\n",
    "for choice in response.choices:\n",
    "\ti+=1\n",
    "\tprint('Resposta' + str(i) + ': ' + choice.message['content'])\n",
    "\n",
    "print('\\n' + '='*50 + '\\n')\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserindo textos\n",
    "Este recurso permite que você controle mais finamente a saída do modelo. Isso é útil para tarefas onde você precisa guiar o modelo em direção a um resultado específico.\n",
    "\n",
    "**Obs:** Não está muito claro como isto funciona. E na [documentação](https://platform.openai.com/docs/guides/gpt/inserting-text) não tem exemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta1: \n",
      "\n",
      "A descoberta do Brasil foi atribuída ao navegador português Pedro Álvares Cabral, em abril de 1500. Cabral e sua frota partiram de Lisboa, Portugal, em 9 de março de 1500, em direção ao Oriente, mas acabaram se desviando para o oceano Atlântico, acabando por descobrir a terra que passou a ser conhecida como Brasil. O nome foi dado em homenagem aos brasileiros, árvore cuja madeira era usada para produzir uma cor laranja avermelhada, que era usado para pintar as embarcações. O Brasil foi colonizado pelos portugueses e, posteriormente, foi anexado à Coroa Portuguesa como sua colônia. Após a independência, em 1822, o Brasil tornou-se um país soberano. \n",
      "\n",
      "Outro fato interessante sobre a descoberta do Brasil é que o nome da colônia foi dado em homenagem a uma bebida originalmente conhecida como caçhaca, que era feita de melaço de cana-de-açúcar temperado com pimenta. Daí, surgiu a expressão brasileira \"caipirinha\", que significa literalmente \"caipira de melaço\". A caipirinha é uma bebida tradicional brasileira, feita com melaço de cana-de-açúcar, limão e \n",
      "\n",
      "==================================================\n",
      "\n",
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"text\": \"\\n\\nA descoberta do Brasil foi atribu\\u00edda ao navegador portugu\\u00eas Pedro \\u00c1lvares Cabral, em abril de 1500. Cabral e sua frota partiram de Lisboa, Portugal, em 9 de mar\\u00e7o de 1500, em dire\\u00e7\\u00e3o ao Oriente, mas acabaram se desviando para o oceano Atl\\u00e2ntico, acabando por descobrir a terra que passou a ser conhecida como Brasil. O nome foi dado em homenagem aos brasileiros, \\u00e1rvore cuja madeira era usada para produzir uma cor laranja avermelhada, que era usado para pintar as embarca\\u00e7\\u00f5es. O Brasil foi colonizado pelos portugueses e, posteriormente, foi anexado \\u00e0 Coroa Portuguesa como sua col\\u00f4nia. Ap\\u00f3s a independ\\u00eancia, em 1822, o Brasil tornou-se um pa\\u00eds soberano. \\n\\nOutro fato interessante sobre a descoberta do Brasil \\u00e9 que o nome da col\\u00f4nia foi dado em homenagem a uma bebida originalmente conhecida como ca\\u00e7haca, que era feita de mela\\u00e7o de cana-de-a\\u00e7\\u00facar temperado com pimenta. Da\\u00ed, surgiu a express\\u00e3o brasileira \\\"caipirinha\\\", que significa literalmente \\\"caipira de mela\\u00e7o\\\". A caipirinha \\u00e9 uma bebida tradicional brasileira, feita com mela\\u00e7o de cana-de-a\\u00e7\\u00facar, lim\\u00e3o e \"\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1692743765,\n",
      "    \"id\": \"cmpl-7qUGjd76fnhjde6fRzijAPDadxerT\",\n",
      "    \"model\": \"text-davinci-003\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 1383,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 1399\n",
      "    },\n",
      "    \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "\tmodel=\"text-davinci-003\",\n",
    "\tprompt=\"Quem descobriu o Brasil?\",\n",
    "\tsuffix=\"chocolate com pimenta\",\n",
    "\ttemperature=0.7,\n",
    "\tbest_of=5,\n",
    "\tmax_tokens=2000,\n",
    ")\n",
    "\n",
    "i=0\n",
    "for choice in response.choices:\n",
    "\ti+=1\n",
    "\tprint('Resposta' + str(i) + ': ' + choice.text)\n",
    "\n",
    "print('\\n' + '='*50 + '\\n')\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
